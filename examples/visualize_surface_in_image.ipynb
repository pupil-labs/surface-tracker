{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surface Tracking - Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing as T"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### API Overview\n",
    "\n",
    "```python3\n",
    "from surface_tracker import SurfaceTracker\n",
    "\n",
    "\n",
    "# Instace implementing the `surface_tracker.CameraModel` interface.\n",
    "#\n",
    "# This version of the library does not provide a concrete implementation of this interface,\n",
    "# so library clients must implement a concrete subclass of `surface_tracker.CameraModel`.\n",
    "camera_model = ...\n",
    "\n",
    "\n",
    "# List of the detected instances of `surface_tracker.Marker` class.\n",
    "detected_markers_in_frame_n = ...\n",
    "\n",
    "\n",
    "# Main entry point of the library API;\n",
    "# used to define and locate surfaces based on\n",
    "# a list of markers and a camera model\n",
    "surface_tracker = SurfaceTracker()\n",
    "\n",
    "\n",
    "my_surface = surface_tracker.define_surface(\n",
    "    name=\"My Surface\",\n",
    "    markers=detected_markers_in_frame_n,\n",
    "    camera_model=camera_model,\n",
    ")\n",
    "\n",
    "\n",
    "detected_markers_in_frame_k = ...\n",
    "\n",
    "\n",
    "surface_location_within_frame_k = surface_tracker.locate_surface(\n",
    "    surface=my_surface,\n",
    "    markers=detected_markers_in_frame_k,\n",
    "    camera_model=camera_model,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surface_tracker import (\n",
    "    CornerId,\n",
    "    Marker, MarkerId,\n",
    "    Surface, SurfaceId,\n",
    "    SurfaceImageCrop,\n",
    "    SurfaceHeatmap,\n",
    "    SurfaceLocation,\n",
    "    SurfaceTracker,\n",
    "    SurfaceVisualAnchors,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing the interfaces\n",
    "\n",
    "Bellow are basic implementations of the parts that are not provided by the library."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Camera model\n",
    "\n",
    "The current version of the `surface_tracker` library does **not** provide a concrete implementation of the `CameraModel` interface.\n",
    "\n",
    "The client of the library **must** implement the interface to be able to use the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Source: pupil/pupil_src/shared_modules/camera_model.py\n",
    "class RadialDistorsionCamera():\n",
    "    \"\"\" Camera model assuming a lense with radial distortion (this is the defaut model in opencv).\n",
    "        Provides functionality to make use of a pinhole camera calibration that is also compensating for lense distortion\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, resolution, K, D):\n",
    "        self.name = name\n",
    "        self.__resolution = resolution\n",
    "        self.K = np.array(K)\n",
    "        self.D = np.array(D)\n",
    "\n",
    "    # CameraModel Interface\n",
    "\n",
    "    @property\n",
    "    def resolution(self) -> T.Tuple[int, int]:\n",
    "        return self.__resolution\n",
    "    \n",
    "    def undistort_points_on_image_plane(self, points):\n",
    "        points = self.__unprojectPoints(points, use_distortion=True)\n",
    "        points = self.__projectPoints(points, use_distortion=False)\n",
    "        return points\n",
    "\n",
    "    def distort_points_on_image_plane(self, points):\n",
    "        points = self.__unprojectPoints(points, use_distortion=False)\n",
    "        points = self.__projectPoints(points, use_distortion=True)\n",
    "        return points\n",
    "\n",
    "    # Private\n",
    "\n",
    "    def __projectPoints(self, object_points, rvec=None, tvec=None, use_distortion=True):\n",
    "        \"\"\"\n",
    "        Projects a set of points onto the camera plane as defined by the camera model.\n",
    "        :param object_points: Set of 3D world points\n",
    "        :param rvec: Set of vectors describing the rotation of the camera when recording the corresponding object point\n",
    "        :param tvec: Set of vectors describing the translation of the camera when recording the corresponding object point\n",
    "        :return: Projected 2D points\n",
    "        \"\"\"\n",
    "        input_dim = object_points.ndim\n",
    "\n",
    "        object_points = object_points.reshape((1, -1, 3))\n",
    "\n",
    "        if rvec is None:\n",
    "            rvec = np.zeros(3).reshape(1, 1, 3)\n",
    "        else:\n",
    "            rvec = np.array(rvec).reshape(1, 1, 3)\n",
    "\n",
    "        if tvec is None:\n",
    "            tvec = np.zeros(3).reshape(1, 1, 3)\n",
    "        else:\n",
    "            tvec = np.array(tvec).reshape(1, 1, 3)\n",
    "\n",
    "        if use_distortion:\n",
    "            _D = self.D\n",
    "        else:\n",
    "            _D = np.asarray([[0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "        image_points, jacobian = cv2.projectPoints(\n",
    "            object_points, rvec, tvec, self.K, _D\n",
    "        )\n",
    "\n",
    "        if input_dim == 2:\n",
    "            image_points.shape = (-1, 2)\n",
    "        elif input_dim == 3:\n",
    "            image_points.shape = (-1, 1, 2)\n",
    "        return image_points\n",
    "\n",
    "    def __unprojectPoints(self, pts_2d, use_distortion=True, normalize=False):\n",
    "        \"\"\"\n",
    "        Undistorts points according to the camera model.\n",
    "        :param pts_2d, shape: Nx2\n",
    "        :return: Array of unprojected 3d points, shape: Nx3\n",
    "        \"\"\"\n",
    "        pts_2d = np.array(pts_2d, dtype=np.float32)\n",
    "\n",
    "        # Delete any posibly wrong 3rd dimension\n",
    "        if pts_2d.ndim == 1 or pts_2d.ndim == 3:\n",
    "            pts_2d = pts_2d.reshape((-1, 2))\n",
    "\n",
    "        # Add third dimension the way cv2 wants it\n",
    "        if pts_2d.ndim == 2:\n",
    "            pts_2d = pts_2d.reshape((-1, 1, 2))\n",
    "\n",
    "        if use_distortion:\n",
    "            _D = self.D\n",
    "        else:\n",
    "            _D = np.asarray([[0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "        pts_2d_undist = cv2.undistortPoints(pts_2d, self.K, _D)\n",
    "\n",
    "        pts_3d = cv2.convertPointsToHomogeneous(pts_2d_undist)\n",
    "        pts_3d.shape = -1, 3\n",
    "\n",
    "        if normalize:\n",
    "            pts_3d /= np.linalg.norm(pts_3d, axis=1)[:, np.newaxis]\n",
    "\n",
    "        return pts_3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_model = RadialDistorsionCamera(\n",
    "    name=\"Radial Distorsion Camera\",\n",
    "    resolution=(1280, 720),\n",
    "    K=[\n",
    "        [829.3510515270362, 0.0, 659.9293047259697],\n",
    "        [0.0, 799.5709408845464, 373.0776462356668],\n",
    "        [0.0, 0.0, 1.0],\n",
    "    ],\n",
    "    D=[\n",
    "        [\n",
    "            -0.43738542863224966,\n",
    "            0.190570781428104,\n",
    "            -0.00125233833830639,\n",
    "            0.0018723428760170056,\n",
    "            -0.039219091259637684,\n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "camera_model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Marker detector\n",
    "\n",
    "This example is using surfaces defined by `apriltag` markers.\n",
    "\n",
    "Bellow is a wrapper around the `apriltag` detector provided by the `pupil_apriltags` library. The most importat part that the wrapper does is construct `surface_tracker.Marker` instances from the `apriltag` detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pupil_apriltags\n",
    "\n",
    "\n",
    "def create_apriltag_marker_uid(tag_family: str, tag_id: int) -> MarkerId:\n",
    "    # Construct the UID by concatinating the tag family and the tag id\n",
    "    return MarkerId(f\"{tag_family}:{tag_id}\")\n",
    "\n",
    "\n",
    "class ApriltagDetector:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *families: T.Set[str],\n",
    "        camera_model,\n",
    "    ):\n",
    "        families = \" \".join(families)\n",
    "        self._camera_model = camera_model\n",
    "        self._detector = pupil_apriltags.Detector(families=families)\n",
    "\n",
    "    def detect_from_image(self, image) -> T.List[Marker]:\n",
    "        gray = rgb_to_gray(image)\n",
    "        return self.detect_from_gray(gray)\n",
    "\n",
    "    def detect_from_gray(self, gray) -> T.List[Marker]:\n",
    "        undist_gray = self._camera_model.undistort_points_on_image_plane(gray)\n",
    "\n",
    "        # Detect apriltag markers from the gray image\n",
    "        markers = self._detector.detect(undist_gray)\n",
    "\n",
    "        # Ensure detected markers are unique\n",
    "        # TODO: Between deplicate markers, pick the one with higher confidence\n",
    "        uid_fn = self.__apiltag_marker_uid\n",
    "        markers = dict((uid_fn(m), m) for m in markers).values()\n",
    "\n",
    "        # Convert apriltag markers into surface tracker markers\n",
    "        marker_fn = self.__apriltag_marker_to_surface_marker\n",
    "        markers = [marker_fn(m) for m in markers]\n",
    "\n",
    "        return markers\n",
    "\n",
    "    @staticmethod\n",
    "    def __apiltag_marker_uid(apriltag_marker: pupil_apriltags.Detection) -> MarkerId:\n",
    "        family = apriltag_marker.tag_family.decode(\"utf-8\")\n",
    "        tag_id = int(apriltag_marker.tag_id)\n",
    "        return create_apriltag_marker_uid(family, tag_id)\n",
    "\n",
    "    @staticmethod\n",
    "    def __apriltag_marker_to_surface_marker(apriltag_marker: pupil_apriltags.Detection) -> Marker:\n",
    "\n",
    "        # Construct the surface tracker marker UID\n",
    "        uid = ApriltagDetector.__apiltag_marker_uid(apriltag_marker)\n",
    "\n",
    "        # Extract vertices in the correct format form apriltag marker\n",
    "        vertices = [[point] for point in apriltag_marker.corners]\n",
    "\n",
    "        # TODO: Verify this is correct...\n",
    "        starting_with = CornerId.TOP_LEFT\n",
    "        clockwise = True\n",
    "\n",
    "        return Marker.from_vertices(\n",
    "            uid=uid,\n",
    "            undistorted_image_space_vertices=vertices,\n",
    "            starting_with=starting_with,\n",
    "            clockwise=clockwise\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, here are some helper functions that load sample images, and visualize images enriched by the data supplied by the `surface_tracker` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "### Loading images\n",
    "\n",
    "\n",
    "def load_image(path: str) -> np.ndarray:\n",
    "    image = Image.open(path)\n",
    "    image = np.asarray(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_sample_image(name: str, frame_index: int) -> np.ndarray:\n",
    "    i = str(frame_index).rjust(5, \"0\")\n",
    "    path = os.path.join(\".\", \"sample_data\", name, \"frames\", f\"{i}.jpg\")\n",
    "    return load_image(path)\n",
    "\n",
    "\n",
    "### Converting images\n",
    "\n",
    "\n",
    "def rgb_to_gray(image: np.ndarray) -> np.ndarray:\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.convert(\"L\")\n",
    "    image = np.asarray(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "### Overlaying information on images\n",
    "\n",
    "\n",
    "def overlay_surface_visual_anchors(image: np.ndarray, anchors: SurfaceVisualAnchors) -> np.ndarray:\n",
    "    image = image.copy()\n",
    "    image = overlay_polyline(image, anchors.top_polyline, color=(0, 0, 255))\n",
    "    image = overlay_polyline(image, anchors.perimeter_polyline, color=(255, 0, 0))\n",
    "    # TODO: Overlay menu edit buttons\n",
    "    return image\n",
    "\n",
    "\n",
    "def overlay_markers(image: np.ndarray, markers: T.List[Marker], color=(0, 255, 0), alpha=0.7) -> np.ndarray:\n",
    "    image = image.copy()\n",
    "    overlay = np.zeros_like(image)\n",
    "    vertices = np.asarray([m.vertices() for m in markers], dtype=np.int32)\n",
    "    overlay = cv2.fillPoly(overlay, vertices, color)\n",
    "    image = cv2.addWeighted(image, 1.0, overlay, alpha, 0.0)\n",
    "\n",
    "    for m in markers:\n",
    "        n = int(str(m.uid).split(\":\")[1])\n",
    "        vertices = m.vertices()\n",
    "        image = overlay_text(image, str(n), vertices[0][0])\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def overlay_polyline(image: np.ndarray, points, color, is_closed=True, thickness=2) -> np.ndarray:\n",
    "    image = image.copy()\n",
    "    points = np.array([points], dtype=np.int32)\n",
    "    return cv2.polylines(image, points, isClosed=is_closed, color=color, thickness=thickness)\n",
    "\n",
    "\n",
    "def overlay_polyfill(image: np.ndarray, points, color) -> np.ndarray:\n",
    "    image = image.copy()\n",
    "    return image  # FIXME\n",
    "\n",
    "\n",
    "def overlay_text(image: np.ndarray, text: str, point, color=(0, 0, 255)) -> np.ndarray:\n",
    "    image = image.copy()\n",
    "\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    FONT_SCALE = 1.0\n",
    "    FONT_THICKNESS = 2\n",
    "\n",
    "    (label_width, label_height), baseline = cv2.getTextSize(text, FONT, FONT_SCALE, FONT_THICKNESS)\n",
    "\n",
    "    point = (\n",
    "        int(point[0]),\n",
    "        int(point[1]),\n",
    "    )\n",
    "\n",
    "    image = cv2.putText(image, text, point, FONT, FONT_SCALE, color, FONT_THICKNESS)\n",
    "    return image\n",
    "\n",
    "\n",
    "def overlay_heatmap_on_cropped_image(\n",
    "    image: np.ndarray,\n",
    "    image_crop: SurfaceImageCrop,\n",
    "    heatmap=SurfaceHeatmap,\n",
    "    heatmap_alpha: float = None\n",
    "):\n",
    "    heatmap_alpha = heatmap_alpha if heatmap_alpha is not None else 0.4\n",
    "\n",
    "    surface_image = image_crop.apply_to_image(image)\n",
    "\n",
    "    heatmap_image = heatmap.image(size=image_crop.size_in_image_space)\n",
    "\n",
    "    return cv2.addWeighted(surface_image, 1.0, heatmap_image, heatmap_alpha, 0.0)\n",
    "\n",
    "\n",
    "### Showing images\n",
    "\n",
    "\n",
    "def show_markers(image: np.ndarray, markers: T.List[Marker]):\n",
    "    image = overlay_markers(image, markers)\n",
    "    show_image(image)\n",
    "\n",
    "\n",
    "def show_heatmap_on_cropped_surface(\n",
    "    image: np.ndarray,\n",
    "    surface: Surface,\n",
    "    surface_tracker: SurfaceTracker,\n",
    "    location: SurfaceLocation,\n",
    "    heatmap_points: T.List[T.Tuple[int, int]],\n",
    "    heatmap_alpha: float = None,\n",
    "    crop_width=None, crop_height=None,\n",
    "    max_width: float=None, max_height: float=None\n",
    "):\n",
    "\n",
    "    image_crop, heatmap = surface_tracker.locate_surface_image_crop_with_heatmap(\n",
    "        surface=surface,\n",
    "        location=location,\n",
    "        points=heatmap_points,\n",
    "        width=crop_width,\n",
    "        height=crop_height,\n",
    "    )\n",
    "\n",
    "    image = overlay_heatmap_on_cropped_image(\n",
    "        image=image,\n",
    "        image_crop=image_crop,\n",
    "        heatmap=heatmap,\n",
    "        heatmap_alpha=heatmap_alpha,\n",
    "    )\n",
    "\n",
    "    show_image(image, max_width=max_width, max_height=max_height)\n",
    "\n",
    "\n",
    "def show_surface(image: np.ndarray, surface: Surface, surface_tracker: SurfaceTracker, marker_detector: ApriltagDetector, max_width: float=None, max_height: float=None):\n",
    "    gray = rgb_to_gray(image)\n",
    "\n",
    "    markers = marker_detector.detect_from_gray(gray)\n",
    "\n",
    "    ignored_markers = []\n",
    "    surface_markers = []\n",
    "    for m in markers:\n",
    "        if m.uid in surface.registered_marker_uids:\n",
    "            surface_markers.append(m)\n",
    "        else:\n",
    "            ignored_markers.append(m)\n",
    "\n",
    "    image = overlay_markers(image, ignored_markers, color=(255, 0, 0), alpha=0.3)\n",
    "    image = overlay_markers(image, surface_markers, color=(0, 255, 0), alpha=0.7)\n",
    "\n",
    "    location = surface_tracker.locate_surface(\n",
    "        surface=surface,\n",
    "        markers=markers,\n",
    "    )\n",
    "    \n",
    "    if location is not None:\n",
    "        # TODO: Overlay surface name\n",
    "        show_location(image, surface, location, surface_tracker, max_width=max_width, max_height=max_height)\n",
    "    else:\n",
    "        show_image(image, max_width=max_width, max_height=max_height)\n",
    "\n",
    "\n",
    "def show_location(image: np.ndarray, surface: Surface, location: SurfaceLocation, surface_tracker: SurfaceTracker, max_width: float=None, max_height: float=None):\n",
    "    visual_anchors = surface_tracker.locate_surface_visual_anchors(\n",
    "        surface=surface,\n",
    "        location=location,\n",
    "    )\n",
    "    show_visual_anchors(image, visual_anchors, max_width=max_width, max_height=max_height)\n",
    "\n",
    "\n",
    "def show_visual_anchors(image: np.ndarray, anchors: SurfaceVisualAnchors, max_width: float=None, max_height: float=None):\n",
    "    image = overlay_surface_visual_anchors(image, anchors)\n",
    "    show_image(image, max_width=max_width, max_height=max_height)\n",
    "\n",
    "\n",
    "def show_image(image: np.ndarray, max_width: float=None, max_height: float=None):\n",
    "    ratio = image.shape[0] / image.shape[1]\n",
    "\n",
    "    dpi = plt.gcf().dpi\n",
    "\n",
    "    if max_width is None and max_height is None:\n",
    "        width_inch = 30 * ratio\n",
    "        height_inch = 30\n",
    "    elif max_width is None:\n",
    "        width_inch = max_height / ratio / dpi\n",
    "        height_inch = max_height / dpi\n",
    "    elif max_height is None:\n",
    "        width_inch = max_width / dpi\n",
    "        height_inch = max_width * ratio / dpi\n",
    "    else:\n",
    "        raise ValueError(\"Must supply EITHER max_width OR max_height\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(width_inch, height_inch))\n",
    "    if len(image.shape) == 2:\n",
    "        ax.imshow(image, interpolation=None, cmap='gray')\n",
    "    else:\n",
    "        ax.imshow(image, interpolation=None)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First, the `1`st frame from the `apriltag_world` video is loaded. This will be used to define the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = load_sample_image(\"apriltag_world\", frame_index=1)\n",
    "show_image(image_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, the `apriltag` detector is run to find all the markers in the image. These markers will define the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriltag_tag_family = \"tagCustom48h12\"\n",
    "apriltag_detector = ApriltagDetector(apriltag_tag_family, camera_model=camera_model)\n",
    "apriltag_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_markers_1 = apriltag_detector.detect_from_image(image_1)\n",
    "print(f\"Detected {len(detected_markers_1)} markers.\")\n",
    "show_markers(image_1, detected_markers_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_matrix = [\n",
    "    [1230, 1025, 820, 615, 410, 205, 0],\n",
    "    [1231, 1026, 821, 616, 411, 206, 1],\n",
    "    [1232, 1027, 822, 617, 412, 207, 2],\n",
    "    [1233, 1028, 823, 618, 413, 208, 3],\n",
    "    [1234, 1029, 824, 619, 414, 209, 4],\n",
    "]\n",
    "\n",
    "\n",
    "for i in range(len(marker_matrix)):\n",
    "    for j in range(len(marker_matrix[i])):\n",
    "        f = apriltag_tag_family\n",
    "        n = marker_matrix[i][j]\n",
    "        marker_matrix[i][j] = create_apriltag_marker_uid(f, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, the `SurfaceTracker` instance is used to define a surface called `\"My Surface\"`. This definition will be used to locate the surface within any frame where a subset of the markers used in the definition are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_tracker = SurfaceTracker()\n",
    "surface_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_surface_marker_uids = [\n",
    "    marker_matrix[1][1], marker_matrix[1][3],\n",
    "    marker_matrix[3][1], marker_matrix[3][3],\n",
    "]\n",
    "\n",
    "my_surface = surface_tracker.define_surface(\n",
    "    name=\"My Surface\",\n",
    "    markers=[m for m in detected_markers_1 if m.uid in my_surface_marker_uids],\n",
    ")\n",
    "print([m for m in detected_markers_1 if m.uid in my_surface_marker_uids])\n",
    "assert my_surface is not None\n",
    "my_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bellow is an example of how to locate the surface. As a test that the definition is correct, the next cell visualizes the surface within the same frame that was used to define the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_surface_location_within_frame_1 = surface_tracker.locate_surface(\n",
    "    surface=my_surface,\n",
    "    markers=detected_markers_1,\n",
    ")\n",
    "assert my_surface_location_within_frame_1 is not None\n",
    "show_location(image_1, my_surface, my_surface_location_within_frame_1, surface_tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, to test that the definition works within any frame, the code bellow loads a different frame, detects the markers preset in the image, locates the surface within the frame, and visualizes the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_4 = load_sample_image(\"apriltag_world\", frame_index=4)\n",
    "show_image(image_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_markers_4 = apriltag_detector.detect_from_image(image_4)\n",
    "print(f\"Detected {len(detected_markers_4)} markers.\")\n",
    "show_markers(image_4, detected_markers_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_surface_location_within_frame_4 = surface_tracker.locate_surface(\n",
    "    surface=my_surface,\n",
    "    markers=detected_markers_4,\n",
    ")\n",
    "assert my_surface_location_within_frame_4 is not None\n",
    "show_location(image_4, my_surface, my_surface_location_within_frame_4, surface_tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add/Remove corner"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The following section will show how to add/remove a corner from the surface definition.\n",
    "\n",
    "To visualize the update, the surface will be drawn togather with the detected markers. The markers that are part of the surface definition will be filled with green, while those that are not part of the definition will be filled with red. Also, the set of the registered markers will be printed after each update to verify that the update did take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_surface(image=image_4, surface=my_surface, surface_tracker=surface_tracker, marker_detector=apriltag_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_surface.registered_marker_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_uids_to_remove = [\n",
    "    marker_matrix[1][3],\n",
    "    marker_matrix[3][3]\n",
    "]\n",
    "\n",
    "surface_tracker.remove_markers_from_surface(\n",
    "    surface=my_surface,\n",
    "    location=my_surface_location_within_frame_4,\n",
    "    marker_uids=marker_uids_to_remove,\n",
    ")\n",
    "\n",
    "my_surface.registered_marker_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_surface(image=image_4, surface=my_surface, surface_tracker=surface_tracker, marker_detector=apriltag_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_surface.registered_marker_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_uids_to_add = [\n",
    "    marker_matrix[0][5],\n",
    "    marker_matrix[4][1],\n",
    "    marker_matrix[4][5],\n",
    "]\n",
    "\n",
    "markers_to_add = [m for m in detected_markers_4 if m.uid in marker_uids_to_add]\n",
    "assert len(markers_to_add) == len(marker_uids_to_add)\n",
    "\n",
    "surface_tracker.add_markers_to_surface(\n",
    "    surface=my_surface,\n",
    "    location=my_surface_location_within_frame_4,\n",
    "    markers=markers_to_add,\n",
    ")\n",
    "\n",
    "my_surface.registered_marker_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_surface(image=image_4, surface=my_surface, surface_tracker=surface_tracker, marker_detector=apriltag_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Current corner position and moving a corner"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A corner's position can be updated with a new position in image space. To move a corner with a certain offset in image space, the user can get the current position, apply the offset, and update the corner with the new position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_surface_corners_with_offsets(\n",
    "    surface: Surface,\n",
    "    location: SurfaceLocation,\n",
    "    offsets_by_corner: T.Mapping[CornerId, T.Tuple[int, int]]\n",
    "):\n",
    "\n",
    "    ordered_corners = list(offsets_by_corner.keys())\n",
    "\n",
    "    old_positions_in_image_space = surface_tracker.surface_corner_positions_in_image_space(\n",
    "        surface=surface,\n",
    "        location=location,\n",
    "        corners=ordered_corners,\n",
    "    )\n",
    "\n",
    "    new_positions_in_image_space = {}\n",
    "\n",
    "    for corner, offset in offsets_by_corner.items():\n",
    "        new_positions_in_image_space[corner] = (\n",
    "            old_positions_in_image_space[corner][0] + offset[0],\n",
    "            old_positions_in_image_space[corner][1] + offset[1],\n",
    "        )\n",
    "\n",
    "    assert len(offsets_by_corner) == len(new_positions_in_image_space)\n",
    "\n",
    "    surface_tracker.move_surface_corner_positions_in_image_space(\n",
    "        surface=surface,\n",
    "        location=location,\n",
    "        new_positions=new_positions_in_image_space,\n",
    "    )\n",
    "\n",
    "\n",
    "# Move top left corner by y+50\n",
    "# Move top right corner by x-20\n",
    "# Move top right corner by y+50\n",
    "# Move bottom right corner by x-20\n",
    "move_surface_corners_with_offsets(\n",
    "    surface=my_surface,\n",
    "    location=my_surface_location_within_frame_1,\n",
    "    offsets_by_corner={\n",
    "        CornerId.TOP_LEFT: (0, +50),\n",
    "        CornerId.TOP_RIGHT: (-20, +50),\n",
    "        CornerId.BOTTOM_RIGHT: (-20, 0),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_surface(image=image_4, surface=my_surface, surface_tracker=surface_tracker, marker_detector=apriltag_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image crop and points heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_surface_location_within_frame_4 = surface_tracker.locate_surface(\n",
    "    surface=my_surface,\n",
    "    markers=detected_markers_4,\n",
    ")\n",
    "assert my_surface_location_within_frame_4 is not None\n",
    "show_location(image_4, my_surface, my_surface_location_within_frame_4, surface_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_within_frame_4 = surface_tracker.locate_surface_image_crop(\n",
    "    surface=my_surface,\n",
    "    location=my_surface_location_within_frame_4,\n",
    "#     width=100,\n",
    "    height=100,\n",
    ")\n",
    "image_crop_4 = crop_within_frame_4.apply_to_image(image=image_4)\n",
    "show_image(image_crop_4, max_height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading gaze points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import types\n",
    "\n",
    "import msgpack\n",
    "\n",
    "def load_pldata_file(directory, topic):\n",
    "\n",
    "    MSGPACK_EXT_CODE = 13\n",
    "\n",
    "    def unpacking_object_hook(obj):\n",
    "        if type(obj) is dict:\n",
    "            return types.MappingProxyType(obj)\n",
    "\n",
    "    def unpacking_ext_hook(code, data):\n",
    "        if code == MSGPACK_EXT_CODE:\n",
    "            return dict(msgpack_bytes=data)\n",
    "        return msgpack.ExtType(code, data)\n",
    "\n",
    "    ts_file = os.path.join(directory, topic + \"_timestamps.npy\")\n",
    "    msgpack_file = os.path.join(directory, topic + \".pldata\")\n",
    "    try:\n",
    "        data = collections.deque()\n",
    "        topics = collections.deque()\n",
    "        data_ts = np.load(ts_file)\n",
    "        with open(msgpack_file, \"rb\") as fh:\n",
    "            for topic, payload in msgpack.Unpacker(fh, raw=False, use_list=False):\n",
    "                d = msgpack.unpackb(\n",
    "                    payload,\n",
    "                    raw=False,\n",
    "                    use_list=False,\n",
    "                    object_hook=unpacking_object_hook,\n",
    "                    ext_hook=unpacking_ext_hook,\n",
    "                )\n",
    "                data.append(d)\n",
    "                topics.append(topic)\n",
    "    except FileNotFoundError:\n",
    "        data = []\n",
    "        data_ts = []\n",
    "        topics = []\n",
    "\n",
    "    return data, data_ts, topics\n",
    "\n",
    "\n",
    "def load_gaze_points_in_image_space(name, camera_model) -> T.List[T.Tuple[int, int]]:\n",
    "\n",
    "    path = os.path.join(\".\", \"sample_data\", name)\n",
    "    gaze_data, gaze_ts, _ = load_pldata_file(path, \"gaze\")\n",
    "\n",
    "    gaze_ts= np.asarray(gaze_ts)\n",
    "    gaze_data = np.asarray(gaze_data, dtype=object)\n",
    "\n",
    "    # Find correct order once and reorder both lists in-place\n",
    "    sorted_idc = np.argsort(gaze_ts)\n",
    "    gaze_ts = gaze_ts[sorted_idc].tolist()\n",
    "    gaze_data = gaze_data[sorted_idc].tolist()\n",
    "\n",
    "    def denormalize(pos, size, flip_y=False):\n",
    "        width, height = size\n",
    "        x = pos[0]\n",
    "        y = pos[1]\n",
    "        x *= width\n",
    "        if flip_y:\n",
    "            y = 1 - y\n",
    "        y *= height\n",
    "        return x, y\n",
    "\n",
    "    def fn(g: dict) -> T.Tuple[int, int]:\n",
    "        return denormalize(g[\"norm_pos\"], camera_model.resolution, flip_y=True)\n",
    "\n",
    "    gaze_data = map(fn, gaze_data)\n",
    "    gaze_data = list(gaze_data)\n",
    "    return gaze_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_data = load_gaze_points_in_image_space(\"apriltag_world\", camera_model)\n",
    "np.asarray(gaze_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_crop_f4, heatmap_f4 = surface_tracker.locate_surface_image_crop_with_heatmap(\n",
    "    surface=my_surface,\n",
    "    location=my_surface_location_within_frame_4,\n",
    "    points=gaze_data,\n",
    ")\n",
    "(image_crop_f4, heatmap_f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_crop_f4.apply_to_image(image_4), max_height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(heatmap_f4.image(size=image_crop_f4.size_in_image_space), max_height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap_on_cropped_surface(\n",
    "    image=image_4,\n",
    "    surface=my_surface,\n",
    "    surface_tracker=surface_tracker,\n",
    "    location=my_surface_location_within_frame_4,\n",
    "    heatmap_points=gaze_data,\n",
    "#     heatmap_alpha=None,\n",
    "#     crop_width=None,\n",
    "#     crop_height=None,\n",
    "    max_height=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
