{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Tracking - Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surface_tracker import (\n",
    "    CameraModel,\n",
    "    CornerId,\n",
    "    Marker, MarkerId,\n",
    "    Surface, SurfaceId,\n",
    "    SurfaceLocation,\n",
    "    SurfaceTracker,\n",
    "    SurfaceVisualAnchors,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Overview\n",
    "\n",
    "```python3\n",
    "from surface_tracker import SurfaceTracker\n",
    "\n",
    "\n",
    "# Instace implementing the `surface_tracker.CameraModel` interface.\n",
    "#\n",
    "# This version of the library does not provide a concrete implementation of this interface,\n",
    "# so library clients must implement a concrete subclass of `surface_tracker.CameraModel`.\n",
    "camera_model = ...\n",
    "\n",
    "\n",
    "# List of the detected instances of `surface_tracker.Marker` class.\n",
    "detected_markers_in_frame_n = ...\n",
    "\n",
    "\n",
    "# Main entry point of the library API;\n",
    "# used to define and locate surfaces based on\n",
    "# a list of markers and a camera model\n",
    "surface_tracker = SurfaceTracker()\n",
    "\n",
    "\n",
    "my_surface = surface_tracker.define_surface(\n",
    "    name=\"My Surface\",\n",
    "    markers=detected_markers_in_frame_n,\n",
    "    camera_model=camera_model,\n",
    ")\n",
    "\n",
    "\n",
    "detected_markers_in_frame_k = ...\n",
    "\n",
    "\n",
    "surface_location_within_frame_k = surface_tracker.locate_surface(\n",
    "    surface=my_surface,\n",
    "    markers=detected_markers_in_frame_k,\n",
    "    camera_model=camera_model,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the interfaces\n",
    "\n",
    "Bellow are basic implementations of the parts that are not provided by the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera model\n",
    "\n",
    "The current version of the `surface_tracker` library does **not** provide a concrete implementation of the `CameraModel` interface.\n",
    "\n",
    "The client of the library **must** implement the interface to be able to use the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Source: pupil/pupil_src/shared_modules/camera_model.py\n",
    "class RadialDistorsionCamera(CameraModel):\n",
    "    \"\"\" Camera model assuming a lense with radial distortion (this is the defaut model in opencv).\n",
    "        Provides functionality to make use of a pinhole camera calibration that is also compensating for lense distortion\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, resolution, K, D):\n",
    "        self.name = name\n",
    "        self.resolution = resolution\n",
    "        self.K = np.array(K)\n",
    "        self.D = np.array(D)\n",
    "\n",
    "    # CameraModel Interface\n",
    "\n",
    "    def undistort_points_on_image_plane(self, points):\n",
    "        points = self.__unprojectPoints(points, use_distortion=True)\n",
    "        points = self.__projectPoints(points, use_distortion=False)\n",
    "        return points\n",
    "\n",
    "    def distort_points_on_image_plane(self, points):\n",
    "        points = self.__unprojectPoints(points, use_distortion=False)\n",
    "        points = self.__projectPoints(points, use_distortion=True)\n",
    "        return points\n",
    "\n",
    "    # Private\n",
    "\n",
    "    def __projectPoints(self, object_points, rvec=None, tvec=None, use_distortion=True):\n",
    "        \"\"\"\n",
    "        Projects a set of points onto the camera plane as defined by the camera model.\n",
    "        :param object_points: Set of 3D world points\n",
    "        :param rvec: Set of vectors describing the rotation of the camera when recording the corresponding object point\n",
    "        :param tvec: Set of vectors describing the translation of the camera when recording the corresponding object point\n",
    "        :return: Projected 2D points\n",
    "        \"\"\"\n",
    "        input_dim = object_points.ndim\n",
    "\n",
    "        object_points = object_points.reshape((1, -1, 3))\n",
    "\n",
    "        if rvec is None:\n",
    "            rvec = np.zeros(3).reshape(1, 1, 3)\n",
    "        else:\n",
    "            rvec = np.array(rvec).reshape(1, 1, 3)\n",
    "\n",
    "        if tvec is None:\n",
    "            tvec = np.zeros(3).reshape(1, 1, 3)\n",
    "        else:\n",
    "            tvec = np.array(tvec).reshape(1, 1, 3)\n",
    "\n",
    "        if use_distortion:\n",
    "            _D = self.D\n",
    "        else:\n",
    "            _D = np.asarray([[0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "        image_points, jacobian = cv2.projectPoints(\n",
    "            object_points, rvec, tvec, self.K, _D\n",
    "        )\n",
    "\n",
    "        if input_dim == 2:\n",
    "            image_points.shape = (-1, 2)\n",
    "        elif input_dim == 3:\n",
    "            image_points.shape = (-1, 1, 2)\n",
    "        return image_points\n",
    "\n",
    "    def __unprojectPoints(self, pts_2d, use_distortion=True, normalize=False):\n",
    "        \"\"\"\n",
    "        Undistorts points according to the camera model.\n",
    "        :param pts_2d, shape: Nx2\n",
    "        :return: Array of unprojected 3d points, shape: Nx3\n",
    "        \"\"\"\n",
    "        pts_2d = np.array(pts_2d, dtype=np.float32)\n",
    "\n",
    "        # Delete any posibly wrong 3rd dimension\n",
    "        if pts_2d.ndim == 1 or pts_2d.ndim == 3:\n",
    "            pts_2d = pts_2d.reshape((-1, 2))\n",
    "\n",
    "        # Add third dimension the way cv2 wants it\n",
    "        if pts_2d.ndim == 2:\n",
    "            pts_2d = pts_2d.reshape((-1, 1, 2))\n",
    "\n",
    "        if use_distortion:\n",
    "            _D = self.D\n",
    "        else:\n",
    "            _D = np.asarray([[0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "        pts_2d_undist = cv2.undistortPoints(pts_2d, self.K, _D)\n",
    "\n",
    "        pts_3d = cv2.convertPointsToHomogeneous(pts_2d_undist)\n",
    "        pts_3d.shape = -1, 3\n",
    "\n",
    "        if normalize:\n",
    "            pts_3d /= np.linalg.norm(pts_3d, axis=1)[:, np.newaxis]\n",
    "\n",
    "        return pts_3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_model = RadialDistorsionCamera(\n",
    "    name=\"Radial Distorsion Camera\",\n",
    "    resolution=(1280, 720),\n",
    "    K=[\n",
    "        [829.3510515270362, 0.0, 659.9293047259697],\n",
    "        [0.0, 799.5709408845464, 373.0776462356668],\n",
    "        [0.0, 0.0, 1.0],\n",
    "    ],\n",
    "    D=[\n",
    "        [\n",
    "            -0.43738542863224966,\n",
    "            0.190570781428104,\n",
    "            -0.00125233833830639,\n",
    "            0.0018723428760170056,\n",
    "            -0.039219091259637684,\n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "camera_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marker detector\n",
    "\n",
    "This example is using surfaces defined by `apriltag` markers.\n",
    "\n",
    "Bellow is a wrapper around the `apriltag` detector provided by the `pupil_apriltags` library. The most importat part that the wrapper does is construct `surface_tracker.Marker` instances from the `apriltag` detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pupil_apriltags\n",
    "\n",
    "\n",
    "class ApriltagDetector:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *families: T.Set[str],\n",
    "    ):\n",
    "        families = \" \".join(families)\n",
    "        self._detector = pupil_apriltags.Detector(families=families)\n",
    "\n",
    "    def detect_from_image(self, image) -> T.List[Marker]:\n",
    "        gray = rgb_to_gray(image)\n",
    "        return self.detect_from_gray(gray)\n",
    "\n",
    "    def detect_from_gray(self, gray) -> T.List[Marker]:\n",
    "        \n",
    "        # Detect apriltag markers from the gray image\n",
    "        markers = self._detector.detect(gray)\n",
    "\n",
    "        # Ensure detected markers are unique\n",
    "        # TODO: Between deplicate markers, pick the one with higher confidence\n",
    "        uid_fn = self.__apriltag_marker_uid\n",
    "        markers = dict((uid_fn(m), m) for m in markers).values()\n",
    "\n",
    "        # Convert apriltag markers into surface tracker markers\n",
    "        marker_fn = self.__apriltag_marker_to_surface_marker\n",
    "        markers = [marker_fn(m) for m in markers]\n",
    "\n",
    "        return markers\n",
    "\n",
    "    @staticmethod\n",
    "    def __apriltag_marker_uid(apriltag_marker: pupil_apriltags.Detection) -> str:\n",
    "        # Construct the UID by concatinating the tag family and the tag id\n",
    "        return f\"{apriltag_marker.tag_family}:{apriltag_marker.tag_id}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __apriltag_marker_to_surface_marker(apriltag_marker: pupil_apriltags.Detection) -> Marker:\n",
    "\n",
    "        # Construct the surface tracker marker UID\n",
    "        uid = ApriltagDetector.__apriltag_marker_uid(apriltag_marker)\n",
    "        uid = MarkerId(uid)\n",
    "\n",
    "        # Extract vertices in the correct format form apriltag marker\n",
    "        vertices = [[point] for point in apriltag_marker.corners]\n",
    "\n",
    "        # TODO: Verify this is correct...\n",
    "        starting_with = CornerId.TOP_LEFT\n",
    "        clockwise = True\n",
    "\n",
    "        return Marker.from_vertices(\n",
    "            uid=uid,\n",
    "            vertices=vertices,\n",
    "            starting_with=starting_with,\n",
    "            clockwise=clockwise\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here are some helper functions that load sample images, and visualize images enriched by the data supplied by the `surface_tracker` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "### Loading images\n",
    "\n",
    "\n",
    "def load_image(path: str) -> np.ndarray:\n",
    "    image = Image.open(path)\n",
    "    image = np.asarray(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_sample_image(name: str, frame_index: int) -> np.ndarray:\n",
    "    i = str(frame_index).rjust(3, \"0\")\n",
    "    path = f\"./sample_data/{name}/frame_{i}.jpg\"\n",
    "    return load_image(path)\n",
    "\n",
    "\n",
    "### Converting images\n",
    "\n",
    "\n",
    "def rgb_to_gray(image: np.ndarray) -> np.ndarray:\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.convert(\"L\")\n",
    "    image = np.asarray(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "### Overlaying information on images\n",
    "\n",
    "\n",
    "def overlay_surface_visual_anchors(image: np.ndarray, anchors: SurfaceVisualAnchors) -> np.ndarray:\n",
    "    image = overlay_polyline(image, anchors.top_polyline, color=(0, 0, 255))\n",
    "    image = overlay_polyline(image, anchors.perimeter_polyline, color=(255, 0, 0))\n",
    "    # TODO: Overlay menu edit buttons\n",
    "    return image\n",
    "\n",
    "\n",
    "def overlay_markers(image: np.ndarray, markers: T.List[Marker], color=(0, 255, 0), alpha=0.7) -> np.ndarray:\n",
    "    vertices = np.asarray([m.vertices() for m in markers], dtype=np.int32)\n",
    "#     vertices = np_markers.reshape((-1, 4, 2))\n",
    "    overlay = np.zeros_like(image)\n",
    "    overlay = cv2.fillPoly(overlay, vertices, color)\n",
    "    image = cv2.addWeighted(image, 1.0, overlay, alpha, 0.0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def overlay_polyline(image: np.ndarray, points, color, is_closed=True, thickness=2) -> np.ndarray:\n",
    "    points = np.array([points], dtype=np.int32)\n",
    "    return cv2.polylines(image, points, isClosed=is_closed, color=color, thickness=thickness)\n",
    "\n",
    "\n",
    "def overlay_polyfill(image: np.ndarray, points, color) -> np.ndarray:\n",
    "    return image  # FIXME\n",
    "\n",
    "\n",
    "def overlay_text(image: np.ndarray, point, text: str) -> np.ndarray:\n",
    "    return image  # FIXME\n",
    "\n",
    "\n",
    "### Showing images\n",
    "\n",
    "\n",
    "def show_markers(image: np.ndarray, markers: T.List[Marker]):\n",
    "    image = overlay_markers(image, markers)\n",
    "    show_image(image)\n",
    "\n",
    "\n",
    "def show_surface(image: np.ndarray, surface: Surface, surface_tracker: SurfaceTracker, camera_model: CameraModel):\n",
    "    gray = rgb_to_gray(image)\n",
    "\n",
    "    markers = self.marker_detector.detect_from_gray(gray)\n",
    "\n",
    "    image = overlay_markers(image, markers)\n",
    "\n",
    "    location = self.surface_tracker.locate_surface(\n",
    "        surface=surface,\n",
    "        markers=markers,\n",
    "        camera_model=camera_model,\n",
    "    )\n",
    "    \n",
    "    if location is not None:\n",
    "        # TODO: Overlay surface name\n",
    "        show_location(image, location, surface_tracker, camera_model)\n",
    "    else:\n",
    "        show_image(image)\n",
    "\n",
    "\n",
    "def show_location(image: np.ndarray, location: SurfaceLocation, surface_tracker: SurfaceTracker, camera_model: CameraModel):\n",
    "    visual_anchors = surface_tracker.locate_visual_anchors(\n",
    "        location=location,\n",
    "        camera_model=camera_model,\n",
    "    )\n",
    "    show_visual_anchors(image, visual_anchors)\n",
    "\n",
    "\n",
    "def show_visual_anchors(image: np.ndarray, anchors: SurfaceVisualAnchors):\n",
    "    image = overlay_surface_visual_anchors(image, anchors)\n",
    "    show_image(image)\n",
    "\n",
    "\n",
    "def show_image(image: np.ndarray, figure_size=30):\n",
    "    ratio = image.shape[0] / image.shape[1]\n",
    "    fig, ax = plt.subplots(figsize=(figure_size*ratio, figure_size))\n",
    "    if len(image.shape) == 2:\n",
    "        ax.imshow(image, interpolation=None, cmap='gray')\n",
    "    else:\n",
    "        ax.imshow(image, interpolation=None)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the `1`st frame from the `apriltag_world` video is loaded. This will be used to define the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = load_sample_image(\"apriltag_world\", frame_index=1)\n",
    "show_image(image_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the `apriltag` detector is run to find all the markers in the image. These markers will define the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriltag_detector = ApriltagDetector(\"tagCustom48h12\")\n",
    "apriltag_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_markers_1 = apriltag_detector.detect_from_image(image_1)\n",
    "print(f\"Detected {len(detected_markers_1)} markers.\")\n",
    "show_markers(image_1, detected_markers_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the `SurfaceTracker` instance is used to define a surface called `\"My Surface\"`. This definition will be used to locate the surface within any frame where a subset of the markers used in the definition are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_tracker = SurfaceTracker()\n",
    "surface_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_surface = surface_tracker.define_surface(\n",
    "    name=\"My Surface\",\n",
    "    markers=detected_markers_1,\n",
    "    camera_model=camera_model,\n",
    ")\n",
    "my_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow is an example of how to locate the surface. As a test that the definition is correct, the next cell visualizes the surface within the same frame that was used to define the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_surface_location_within_frame_1 = surface_tracker.locate_surface(\n",
    "    surface=my_surface,\n",
    "    markers=detected_markers_1,\n",
    "    camera_model=camera_model,\n",
    ")\n",
    "show_location(image_1, my_surface_location_within_frame_1, surface_tracker, camera_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to test that the definition works within any frame, the code bellow loads a different frame, detects the markers preset in the image, locates the surface within the frame, and visualizes the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_4 = load_sample_image(\"apriltag_world\", frame_index=4)\n",
    "show_image(image_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_markers_4 = apriltag_detector.detect_from_image(image_4)\n",
    "print(f\"Detected {len(detected_markers_4)} markers.\")\n",
    "show_markers(image_4, detected_markers_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_surface_location_within_frame_4 = surface_tracker.locate_surface(\n",
    "    surface=my_surface,\n",
    "    markers=detected_markers_4,\n",
    "    camera_model=camera_model,\n",
    ")\n",
    "show_location(image_4, my_surface_location_within_frame_4, surface_tracker, camera_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
